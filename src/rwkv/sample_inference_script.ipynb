{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import RwkvModel, DefaultDataCollator, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "from models import RWKV_TOKENIZER, RwkvModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "#torch.cuda.set_per_process_memory_fraction(0.7, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RwkvModelForSequenceClassification.from_pretrained(PATH+'model/raven-0.4b-world', num_labels=3,pad_token_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    PATH+'output_dir',\n",
    "    is_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "tokenizer = RWKV_TOKENIZER(PATH+'rwkv_vocab_v20230424.txt')\n",
    "pad_token_id = 0\n",
    "\n",
    "def tokenization_rwkv(example):\n",
    "    inputs_ids = [tokenizer.encode(d) for d in example[\"data\"]]\n",
    "    #pad the inputs_ids with pad_token_id to max_length or truncate the inputs_ids to max_length\n",
    "    inputs_ids = [ids + [pad_token_id] * (max_length - len(ids)) if len(ids) < max_length else ids[:max_length] for ids in inputs_ids]\n",
    "    labels = example['labels'].copy()\n",
    "    example['input_ids']=inputs_ids\n",
    "    example['labels']=labels\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "tokenizer = RWKV_TOKENIZER(PATH+'rwkv_vocab_v20230424.txt')\n",
    "pad_token_id = 0\n",
    "\n",
    "def tokenization_rwkv(example):\n",
    "    inputs_ids = [tokenizer.encode(d) for d in example[\"news\"]]\n",
    "    #pad the inputs_ids with pad_token_id to max_length or truncate the inputs_ids to max_length\n",
    "    inputs_ids = [ids + [pad_token_id] * (max_length - len(ids)) if len(ids) < max_length else ids[:max_length] for ids in inputs_ids]\n",
    "    labels = example['label'].copy()\n",
    "    example['input_ids']=inputs_ids\n",
    "    example['labels']=labels\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset('csv', data_files={\"test\":PATH+'data/test_small.csv'})\n",
    "\n",
    "ds = ds.map(tokenization_rwkv ,remove_columns=['news','length','label'],batched=True)\n",
    "test_ds = ds['test']\n",
    "\n",
    "test_dataloader = DataLoader(test_ds, batch_size=32, num_workers=10,pin_memory=True,collate_fn=DefaultDataCollator(return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "predictor = Trainer(model=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH+'data/test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'non-hate':0, 'offensive':1, 'hate':2}\n",
    "df['label'] = df['labels'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "probas = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0,5044,26):\n",
    "        ds = datasets.Dataset.from_pandas(df.iloc[i:i+26])\n",
    "        ds = ds.map(tokenization_rwkv ,remove_columns=['news','length','label'],batched=True)\n",
    "        y_pred = predictor.predict(ds)\n",
    "        y_preds.extend(np.argmax(y_pred.predictions[0], axis=1))\n",
    "        probas.extend(y_pred.predictions[0])\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preds'] = y_preds\n",
    "df['probas'] = probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['label'], df['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['label'], df['preds'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(PATH+'data/test_small_preds_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['label'], df['preds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['label'], df['preds'], zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
